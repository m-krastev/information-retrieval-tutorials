{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from argparse import Namespace\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "from tqdm.notebook import trange\n",
    "\n",
    "from ltr.utils import seed\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 2: Counterfactual LTR"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ltr.dataset import load_data\n",
    "\n",
    "data = load_data()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We assume that there is a logging policy that shows the results for each query to the users and logs the user clicks.\n",
    "For that, we provide a logging policy simulator `LoggingPolicy`.\n",
    "Our logging policy only shows top 20 documents to the users.\n",
    "You can use this simulator to:\n",
    "- Get the position of the documents for a query in the SERP: `query_positions`.\n",
    "- Gather the (simulated) clicks of users for a query: `gather_clicks`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clicks for session 1 on documents [32 83 99] on positions [ 3 11  0]\n",
      "clicks for session 2 on documents [68 99] on positions [10  0]\n",
      "clicks for session 3 on documents [99] on positions [0]\n",
      "clicks for session 4 on documents [33 99] on positions [1 0]\n",
      "clicks for session 5 on documents [33 99] on positions [1 0]\n",
      "clicks for session 6 on documents [83 99] on positions [11  0]\n",
      "clicks for session 7 on documents [99] on positions [0]\n",
      "clicks for session 8 on documents [33 99] on positions [1 0]\n",
      "clicks for session 9 on documents [33] on positions [1]\n",
      "clicks for session 10 on documents [33 99] on positions [1 0]\n"
     ]
    }
   ],
   "source": [
    "from ltr.logging_policy import LoggingPolicy\n",
    "\n",
    "logging_policy = LoggingPolicy()\n",
    "\n",
    "# Gather the clicks on the SERP for query 20\n",
    "for i in range(10):\n",
    "    clicked_docs = np.where(logging_policy.gather_clicks(20))[0]\n",
    "    clicked_positions = logging_policy.query_positions(20)[clicked_docs]\n",
    "    print(f'clicks for session {i+1} on documents', clicked_docs, 'on positions', clicked_positions)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Utils\n",
    "\n",
    "### Click data loader\n",
    "First, we need to have a data loader that feeds the model with features and click data.\n",
    "In this data loader, you have to select `topk=20` items for each query, and return three tensors:\n",
    "- Feature vectors of the selected documents,\n",
    "- One instance of the clicks over the selected documents, using the `gather_clicks(qid)` function, and\n",
    "- The positions of the selected documents in the SERP.\n",
    "\n",
    "**IMPORTANT** Here you *should not* use the `labels` for training. It is assumed that we cannot observe the real labels and want to use the `clicks` to train our LTR model instead.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 20, 15]) torch.Size([1, 20]) torch.Size([1, 20])\n",
      "clicks: tensor([[0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]])\n",
      "positions: tensor([[ 3,  4, 18, 19,  1, 10,  6,  2, 12, 15,  5, 16,  7, 11, 17,  9,  8,  0,\n",
      "         14, 13]])\n"
     ]
    }
   ],
   "source": [
    "from ltr.dataset import ClickLTRData\n",
    "\n",
    "clickdataset = ClickLTRData(data, logging_policy)\n",
    "clickdataset[0]\n",
    "train_dl = DataLoader(clickdataset, batch_size=1, shuffle=True)\n",
    "\n",
    "for features, clicks, positions in train_dl:\n",
    "    print(features.shape, clicks.shape, positions.shape)\n",
    "    assert positions.dtype == torch.long\n",
    "    print('clicks:', clicks)\n",
    "    print('positions:', positions)\n",
    "    break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LTR model\n",
    "Further, let's modify the `LTRModel` from previous chapter and take the width of the middle layer as an argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LTRModel(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=15, out_features=20, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=20, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from ltr.model import LTRModel\n",
    "\n",
    "net = LTRModel(data.num_features, width=20)\n",
    "print(net)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ListNet\n",
    "\n",
    "In the previous chapter, you have implemented different loss functions for LTR.\n",
    "Here we use another well known listwise loss funtion, called `ListNet`, and will use it for our unbiased LTR model.\n",
    "The idea behind ListNet is very simple:\n",
    "To solve the discontinuity issue of NDCG, in **ListNet**, the loss function is based on probability distribution on permutations.\n",
    "\n",
    "Define a family of distributions on permutation of scores $z$, $P_z(\\pi)$, s.t. $\\sum_{\\pi\\in\\Omega} P_z(\\pi)=1$, where $\\Omega$ is the set of all $n!$ permutations.\n",
    "Ideally, we want the scores of our LTR model lead to the same permutation distribution as the labels $y$, i.e.,\n",
    "\n",
    "$$\n",
    "\\min KL(P_y,P_z)=-\\sum_{\\pi\\in\\Omega} P_y(\\pi) \\log P_z(\\pi)\n",
    "$$\n",
    "\n",
    "Plackett-Luce distribution gives a general formula for calculating the permutation distribution:\n",
    "\n",
    "$$\n",
    "P_z(\\pi) = \\prod_{j=1}^{n} \\frac{\\exp(z_{\\pi(j)})}{\\sum_{k=j}^{n} \\exp(z_{\\pi(k)})}\n",
    "$$\n",
    "In ListNet, instead of calculating $n!$ permutation probabilities, the top one probability of each document is calculated:\n",
    "\n",
    "$$\n",
    "P_z(j) = \\sum_{\\pi(1)=j, \\pi\\in\\Omega} P_z(\\pi) = \\frac{\\exp(z_{j})}{\\sum_{k=1}^{n} \\exp(z_{k})},\n",
    "$$\n",
    "which is the softmax function.\n",
    "\n",
    "Then, the loss is defined as follows:\n",
    "\n",
    "$$\n",
    "\\mathcal{L}_{\\text{ListNet}}=-\\sum_{j=1}^{n} P_y(j) \\log P_z(j),\n",
    "$$\n",
    "where the softmax function is used to calculate $P_y(j)$ and $P_z(j)$ from the labels and predictions, respectively."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ListNet loss function\n",
    "Implement the ListNet loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 20, 15]) torch.Size([1, 20]) torch.Size([1, 20])\n",
      "torch.Size([1, 20, 1]) torch.Size([1, 20])\n",
      "(tensor(3.8103, grad_fn=<NegBackward0>), {'preds_smax': tensor([[0.0577, 0.0187, 0.0224, 0.0042, 0.0119, 0.0175, 0.0008, 0.0712, 0.0093,\n",
      "         0.0091, 0.1041, 0.0005, 0.1686, 0.0065, 0.0135, 0.1378, 0.1765, 0.0942,\n",
      "         0.0441, 0.0315]], grad_fn=<AddBackward0>), 'true_smax': tensor([[0.0427, 0.0427, 0.0427, 0.0427, 0.0427, 0.0427, 0.0427, 0.0427, 0.0427,\n",
      "         0.1160, 0.1160, 0.0427, 0.0427, 0.0427, 0.0427, 0.0427, 0.0427, 0.0427,\n",
      "         0.0427, 0.0427]]), 'preds_log': tensor([[-2.8527, -3.9800, -3.7996, -5.4684, -4.4338, -4.0461, -7.1720, -2.6417,\n",
      "         -4.6736, -4.7045, -2.2624, -7.5139, -1.7805, -5.0344, -4.3082, -1.9819,\n",
      "         -1.7343, -2.3624, -3.1208, -3.4591]], grad_fn=<LogBackward0>)})\n"
     ]
    }
   ],
   "source": [
    "from ltr.loss import listNet_loss\n",
    " \n",
    "biased_net = LTRModel(data.num_features, width=20)\n",
    "\n",
    "for features, clicks, positions in train_dl:\n",
    "    print(features.shape, clicks.shape, positions.shape)\n",
    "    output = biased_net(features)\n",
    "    print(output.shape, clicks.shape)\n",
    "    loss = listNet_loss(output, clicks, grading=True)\n",
    "    print(loss)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 20, 15]) torch.Size([1, 20]) torch.Size([1, 20])\n",
      "torch.Size([1, 20, 1]) torch.Size([1, 20])\n",
      "(tensor(3.8466, grad_fn=<NegBackward0>), {'preds_smax': tensor([[2.4379e-03, 3.2630e-02, 6.0620e-02, 5.7648e-02, 1.1180e-01, 5.1229e-02,\n",
      "         2.1655e-02, 6.4110e-02, 8.4351e-03, 6.0620e-02, 6.4110e-02, 4.5062e-03,\n",
      "         3.5525e-02, 3.5713e-05, 1.0009e-01, 6.4110e-02, 8.9582e-02, 8.0152e-02,\n",
      "         1.0553e-02, 8.0152e-02]], grad_fn=<AddBackward0>), 'true_smax': tensor([[0.1252, 0.0460, 0.0460, 0.0460, 0.0460, 0.0460, 0.0460, 0.0460, 0.0460,\n",
      "         0.0460, 0.0460, 0.0460, 0.0460, 0.0460, 0.0460, 0.0460, 0.0460, 0.0460,\n",
      "         0.0460, 0.0460]]), 'preds_log': tensor([[ -6.0166,  -3.4225,  -2.8031,  -2.8534,  -2.1911,  -2.9714,  -3.8325,\n",
      "          -2.7471,  -4.7753,  -2.8031,  -2.7471,  -5.4023,  -3.3375, -10.2400,\n",
      "          -2.3017,  -2.7471,  -2.4126,  -2.5238,  -4.5514,  -2.5238]],\n",
      "       grad_fn=<LogBackward0>)})\n"
     ]
    }
   ],
   "source": [
    "from ltr.loss import listNet_loss\n",
    " \n",
    "biased_net = LTRModel(data.num_features, width=20)\n",
    "\n",
    "for features, clicks, positions in train_dl:\n",
    "    print(features.shape, clicks.shape, positions.shape)\n",
    "    output = biased_net(features)\n",
    "    print(output.shape, clicks.shape)\n",
    "    loss = listNet_loss(output, clicks, grading=True)\n",
    "    print(loss)\n",
    "    break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Biased ListNet training\n",
    "Now use `listNet_loss` to train an LTR model. Since we use `clicks` instead of `relevance`, and do not correct for the bias, this would be a biased model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'metrics_val': [{'dcg': (8.26553863412485, 10.431545847952842),\n",
       "   'dcg@03': (2.310110406337027, 5.32496192253306),\n",
       "   'dcg@05': (2.7169339562659, 5.73921879602527),\n",
       "   'dcg@10': (3.4228964878172508, 6.427633209476259),\n",
       "   'dcg@20': (4.419667724619148, 7.11888648036029),\n",
       "   'ndcg': (0.32144478682182104, 0.21623656760878693),\n",
       "   'ndcg@03': (0.10862760481278075, 0.25926073996031457),\n",
       "   'ndcg@05': (0.12029562799900961, 0.2584086063180539),\n",
       "   'ndcg@10': (0.1457863699458244, 0.26263358222164407),\n",
       "   'ndcg@20': (0.1775675757660967, 0.26232603188446946),\n",
       "   'precision@01': (0.10989010989010989, 0.3127527356210485),\n",
       "   'precision@03': (0.0695970695970696, 0.1602537938038634),\n",
       "   'precision@05': (0.054945054945054944, 0.11698007368941771),\n",
       "   'precision@10': (0.04450549450549451, 0.08285779869737818),\n",
       "   'precision@20': (0.035989010989010986, 0.05750164727797976),\n",
       "   'recall@01': (0.06439810189810188, 0.2195271097072441),\n",
       "   'recall@03': (0.10671233528376385, 0.2737938435660403),\n",
       "   'recall@05': (0.13077160934303791, 0.297993918915121),\n",
       "   'recall@10': (0.20389656131414374, 0.36124946962062227),\n",
       "   'recall@20': (0.3005210906309807, 0.40888322315563047),\n",
       "   'relevant rank': (49.34013605442177, 34.034762127684466),\n",
       "   'relevant rank per query': (119.55494505494505, 163.29493559822956)},\n",
       "  {'dcg': (8.027057245463606, 9.840427340166864),\n",
       "   'dcg@03': (1.873181501483539, 4.727853981502057),\n",
       "   'dcg@05': (2.3452864864801866, 5.119084599395124),\n",
       "   'dcg@10': (3.1788258299041527, 5.949414032272898),\n",
       "   'dcg@20': (4.113261209417919, 6.4592804959473415),\n",
       "   'ndcg': (0.3125960375573607, 0.19364771351662272),\n",
       "   'ndcg@03': (0.08762940057504204, 0.2306577088446681),\n",
       "   'ndcg@05': (0.1036112118534991, 0.23375788809808487),\n",
       "   'ndcg@10': (0.13179182658948424, 0.23773013663951642),\n",
       "   'ndcg@20': (0.1626092755896889, 0.23793666142561928),\n",
       "   'precision@01': (0.07142857142857142, 0.25753937681885636),\n",
       "   'precision@03': (0.062271062271062265, 0.15558066360143075),\n",
       "   'precision@05': (0.054945054945054944, 0.11884400733710573),\n",
       "   'precision@10': (0.046153846153846156, 0.08555917213108453),\n",
       "   'precision@20': (0.03571428571428571, 0.053341999557548356),\n",
       "   'recall@01': (0.048305860805860815, 0.19348109763668422),\n",
       "   'recall@03': (0.0905701441415727, 0.2488991266816164),\n",
       "   'recall@05': (0.13599793064078777, 0.30004494271605747),\n",
       "   'recall@10': (0.20244238362370232, 0.3484983864883221),\n",
       "   'recall@20': (0.3014230275219286, 0.3941741767651492),\n",
       "   'relevant rank': (48.229024943310655, 34.57535949318934),\n",
       "   'relevant rank per query': (116.86263736263736, 179.96983211684451)},\n",
       "  {'dcg': (9.812943898317757, 10.501719167979322),\n",
       "   'dcg@03': (3.8766456898535218, 6.437102839742094),\n",
       "   'dcg@05': (4.588239912151751, 6.6857765695419555),\n",
       "   'dcg@10': (5.469396372714642, 7.060982504854398),\n",
       "   'dcg@20': (6.419211823339544, 7.633648184842227),\n",
       "   'ndcg': (0.40244173493326374, 0.24633739918470987),\n",
       "   'ndcg@03': (0.18740410014170553, 0.31748825078895926),\n",
       "   'ndcg@05': (0.2183142022023111, 0.3123581691137883),\n",
       "   'ndcg@10': (0.24703765036447797, 0.30633403304686146),\n",
       "   'ndcg@20': (0.28151572460871216, 0.2986606981519428),\n",
       "   'precision@01': (0.1813186813186813, 0.38528199688479586),\n",
       "   'precision@03': (0.12454212454212453, 0.19858074972058315),\n",
       "   'precision@05': (0.10219780219780221, 0.14023373109144963),\n",
       "   'precision@10': (0.06923076923076923, 0.08731943088052278),\n",
       "   'precision@20': (0.04835164835164835, 0.0576320983568983),\n",
       "   'recall@01': (0.11405677655677655, 0.28222360539665936),\n",
       "   'recall@03': (0.19383949383949386, 0.34089212983283973),\n",
       "   'recall@05': (0.2819125929016039, 0.3977160974999509),\n",
       "   'recall@10': (0.3470604029669963, 0.41406880372049504),\n",
       "   'recall@20': (0.4584350631053928, 0.4272501898754685),\n",
       "   'relevant rank': (40.15873015873016, 34.26013890313172),\n",
       "   'relevant rank per query': (97.3076923076923, 167.41910904283458)},\n",
       "  {'dcg': (11.102245345627097, 10.709266604544448),\n",
       "   'dcg@03': (5.3221183541941945, 7.1688020915883675),\n",
       "   'dcg@05': (6.227472513715871, 7.4543194727718145),\n",
       "   'dcg@10': (7.175778859619625, 7.618744568451932),\n",
       "   'dcg@20': (8.11600571641538, 8.123527847089148),\n",
       "   'ndcg': (0.4666738858801584, 0.2627875339496453),\n",
       "   'ndcg@03': (0.2641391684929672, 0.3514589432491022),\n",
       "   'ndcg@05': (0.29862646913958313, 0.3420789003260228),\n",
       "   'ndcg@10': (0.3342598305493311, 0.32897755453083494),\n",
       "   'ndcg@20': (0.3662020801123894, 0.3173877424604933),\n",
       "   'precision@01': (0.25274725274725274, 0.4345872512809932),\n",
       "   'precision@03': (0.16849816849816848, 0.2175096386711139),\n",
       "   'precision@05': (0.13406593406593406, 0.15564102133059532),\n",
       "   'precision@10': (0.08846153846153847, 0.09035246096276925),\n",
       "   'precision@20': (0.057692307692307696, 0.059264297631841004),\n",
       "   'recall@01': (0.1603021978021978, 0.32108615975373594),\n",
       "   'recall@03': (0.28957352171637885, 0.3961438572864647),\n",
       "   'recall@05': (0.3784577144467254, 0.4268181411342452),\n",
       "   'recall@10': (0.4846769530835464, 0.43474111238619906),\n",
       "   'recall@20': (0.5762190648179659, 0.4220322700215877),\n",
       "   'relevant rank': (35.17460317460318, 33.70418047223689),\n",
       "   'relevant rank per query': (85.23076923076923, 157.97419993297393)},\n",
       "  {'dcg': (12.90564619760851, 11.46881008198957),\n",
       "   'dcg@03': (7.4389528540476935, 7.8778422771783285),\n",
       "   'dcg@05': (8.548605876107024, 8.432070725649574),\n",
       "   'dcg@10': (9.376999079845861, 8.724133594722703),\n",
       "   'dcg@20': (10.37921498558225, 9.0468445506595),\n",
       "   'ndcg': (0.5592327561023716, 0.2829364907908257),\n",
       "   'ndcg@03': (0.38791218089256474, 0.3889271047645043),\n",
       "   'ndcg@05': (0.4209003274541108, 0.3737821062128716),\n",
       "   'ndcg@10': (0.4465260727633569, 0.3593257594758139),\n",
       "   'ndcg@20': (0.48147951443795184, 0.33599256280686013),\n",
       "   'precision@01': (0.37362637362637363, 0.48376616929791516),\n",
       "   'precision@03': (0.23443223443223443, 0.22910616514449655),\n",
       "   'precision@05': (0.17912087912087912, 0.17226129112834712),\n",
       "   'precision@10': (0.1076923076923077, 0.10242206281762448),\n",
       "   'precision@20': (0.06813186813186814, 0.06420112778291356),\n",
       "   'recall@01': (0.24258895866038724, 0.37723305545883856),\n",
       "   'recall@03': (0.43645342752485616, 0.43925168554144906),\n",
       "   'recall@05': (0.5208462782638607, 0.44377875184871235),\n",
       "   'recall@10': (0.5871869430935365, 0.43273539094068264),\n",
       "   'recall@20': (0.6936975570217329, 0.3898000621607844),\n",
       "   'relevant rank': (27.829931972789115, 30.29395833055233),\n",
       "   'relevant rank per query': (67.43406593406593, 142.69087291462796)},\n",
       "  {'dcg': (13.847328657330726, 11.65756215009305),\n",
       "   'dcg@03': (8.694321894322423, 8.4344912367253),\n",
       "   'dcg@05': (9.592631652938282, 8.673218562337443),\n",
       "   'dcg@10': (10.596522508873955, 9.070315762070228),\n",
       "   'dcg@20': (11.436466268012406, 9.309171314006718),\n",
       "   'ndcg': (0.613709970040284, 0.29489528587431874),\n",
       "   'ndcg@03': (0.4607557591924017, 0.41115456712028203),\n",
       "   'ndcg@05': (0.48484583549855076, 0.389244699252107),\n",
       "   'ndcg@10': (0.5164866517658747, 0.3659814609530452),\n",
       "   'ndcg@20': (0.5419888428430242, 0.3495175859054279),\n",
       "   'precision@01': (0.4725274725274725, 0.4992446897406834),\n",
       "   'precision@03': (0.2582417582417582, 0.24179292680479808),\n",
       "   'precision@05': (0.189010989010989, 0.16867326465362545),\n",
       "   'precision@10': (0.11868131868131869, 0.10885224173221794),\n",
       "   'precision@20': (0.07005494505494506, 0.0635185985807017),\n",
       "   'recall@01': (0.3241823652537938, 0.41446210866864835),\n",
       "   'recall@03': (0.48512142619285475, 0.4486223487075636),\n",
       "   'recall@05': (0.5557845542735653, 0.4370123655057298),\n",
       "   'recall@10': (0.6390142824208758, 0.4105024980367664),\n",
       "   'recall@20': (0.7148056156297914, 0.38338094520687216),\n",
       "   'relevant rank': (27.367346938775512, 31.16340118204967),\n",
       "   'relevant rank per query': (66.31318681318682, 146.83105243093536)},\n",
       "  {'dcg': (13.66276479568275, 11.587949873026714),\n",
       "   'dcg@03': (8.531625454267475, 8.203620871394154),\n",
       "   'dcg@05': (9.27646496488389, 8.508729633307908),\n",
       "   'dcg@10': (10.340198438779742, 8.996450315534062),\n",
       "   'dcg@20': (11.285534133341173, 9.425458212841406),\n",
       "   'ndcg': (0.6100309174396366, 0.2941423631436767),\n",
       "   'ndcg@03': (0.46078537692221366, 0.4040944578492056),\n",
       "   'ndcg@05': (0.478090934178394, 0.38890476940878194),\n",
       "   'ndcg@10': (0.5104390437920717, 0.36909601947937465),\n",
       "   'ndcg@20': (0.5383843252142309, 0.3513063624475801),\n",
       "   'precision@01': (0.43956043956043955, 0.4963336171708226),\n",
       "   'precision@03': (0.25824175824175827, 0.24179292680479808),\n",
       "   'precision@05': (0.1813186813186813, 0.16602137285426513),\n",
       "   'precision@10': (0.11538461538461539, 0.10784917930888173),\n",
       "   'precision@20': (0.07115384615384616, 0.06878289192430655),\n",
       "   'recall@01': (0.30732600732600734, 0.41148487622892416),\n",
       "   'recall@03': (0.4795958620134445, 0.44613091077277117),\n",
       "   'recall@05': (0.5400835885725995, 0.4429075942698841),\n",
       "   'recall@10': (0.627003536756284, 0.4181697877388267),\n",
       "   'recall@20': (0.7049571307813066, 0.38573567213715015),\n",
       "   'relevant rank': (26.89342403628118, 30.28496520972797),\n",
       "   'relevant rank per query': (65.16483516483517, 148.21070268306534)},\n",
       "  {'dcg': (12.37018946791656, 10.909875053019372),\n",
       "   'dcg@03': (6.41288366571436, 7.615073906386545),\n",
       "   'dcg@05': (7.613957276928058, 7.753969669161031),\n",
       "   'dcg@10': (8.903790237180134, 8.368648300132206),\n",
       "   'dcg@20': (10.016988483711108, 8.503606571844642),\n",
       "   'ndcg': (0.5473290584356328, 0.26776507310480735),\n",
       "   'ndcg@03': (0.34696402820883093, 0.38530928038326145),\n",
       "   'ndcg@05': (0.39396631857276027, 0.3640759351901125),\n",
       "   'ndcg@10': (0.44253635354010723, 0.34507682866530126),\n",
       "   'ndcg@20': (0.48009133359222855, 0.31706360562749963),\n",
       "   'precision@01': (0.29120879120879123, 0.4543195253689916),\n",
       "   'precision@03': (0.2032967032967033, 0.23086369367288312),\n",
       "   'precision@05': (0.16703296703296702, 0.15901824144096466),\n",
       "   'precision@10': (0.11373626373626373, 0.10832539859905768),\n",
       "   'precision@20': (0.07280219780219781, 0.06516550691794672),\n",
       "   'recall@01': (0.20705128205128204, 0.3665801243959381),\n",
       "   'recall@03': (0.3823431147606972, 0.44098111026218123),\n",
       "   'recall@05': (0.5046047816652213, 0.4473553451269634),\n",
       "   'recall@10': (0.6357843164161845, 0.4272989006311589),\n",
       "   'recall@20': (0.747134001529606, 0.3649732946293168),\n",
       "   'relevant rank': (25.780045351473923, 28.446778264835846),\n",
       "   'relevant rank per query': (62.467032967032964, 152.2815369491401)},\n",
       "  {'dcg': (14.651934024520271, 11.842558079544846),\n",
       "   'dcg@03': (9.6798519855129, 8.436537189985268),\n",
       "   'dcg@05': (10.6256738898969, 8.690908367961542),\n",
       "   'dcg@10': (11.522126795928788, 9.149647217990822),\n",
       "   'dcg@20': (12.447897568630987, 9.743817697998642),\n",
       "   'ndcg': (0.6609585261701569, 0.2928186638742157),\n",
       "   'ndcg@03': (0.5250264388277378, 0.40732594094111835),\n",
       "   'ndcg@05': (0.5477161661434946, 0.3853649009003146),\n",
       "   'ndcg@10': (0.5709997365724159, 0.365453605722101),\n",
       "   'ndcg@20': (0.5971602245880424, 0.3476285200508049),\n",
       "   'precision@01': (0.5164835164835165, 0.49972821981987137),\n",
       "   'precision@03': (0.2838827838827839, 0.24583776365847793),\n",
       "   'precision@05': (0.20769230769230768, 0.17335143066111966),\n",
       "   'precision@10': (0.12637362637362637, 0.1112715368314262),\n",
       "   'precision@20': (0.0760989010989011, 0.07238215962348353),\n",
       "   'recall@01': (0.35718864468864464, 0.4228549463859004),\n",
       "   'recall@03': (0.5343430379144666, 0.44363527535132846),\n",
       "   'recall@05': (0.6002192862082971, 0.4256444559229271),\n",
       "   'recall@10': (0.6750199434265368, 0.3949516904008394),\n",
       "   'recall@20': (0.747918336242512, 0.3611643402461959),\n",
       "   'relevant rank': (24.17233560090703, 29.264022260334592),\n",
       "   'relevant rank per query': (58.57142857142857, 146.12347201522198)},\n",
       "  {'dcg': (13.735898793012067, 11.672162441024216),\n",
       "   'dcg@03': (8.272597587692374, 8.36067179556255),\n",
       "   'dcg@05': (9.150433303361838, 8.646018784620319),\n",
       "   'dcg@10': (10.449878923602384, 9.047518675553974),\n",
       "   'dcg@20': (11.52254631949859, 9.513815595798231),\n",
       "   'ndcg': (0.6118406727159437, 0.28843950848845173),\n",
       "   'ndcg@03': (0.44290246165676833, 0.4111840341368095),\n",
       "   'ndcg@05': (0.4710857514245712, 0.3923284687847955),\n",
       "   'ndcg@10': (0.5151434810455815, 0.36357195894857847),\n",
       "   'ndcg@20': (0.5489898885290508, 0.3394825548983691),\n",
       "   'precision@01': (0.43956043956043955, 0.4963336171708226),\n",
       "   'precision@03': (0.24908424908424906, 0.24256165759916926),\n",
       "   'precision@05': (0.18021978021978022, 0.16655512912340564),\n",
       "   'precision@10': (0.12197802197802197, 0.11024667426864278),\n",
       "   'precision@20': (0.07637362637362638, 0.07294460465577887),\n",
       "   'recall@01': (0.3052655677655678, 0.41145380853209873),\n",
       "   'recall@03': (0.46023381380524236, 0.44807937785873525),\n",
       "   'recall@05': (0.5320666055556166, 0.4495396384070773),\n",
       "   'recall@10': (0.6622951682017616, 0.40806716008730387),\n",
       "   'recall@20': (0.7593616548286877, 0.3643702046071525),\n",
       "   'relevant rank': (23.970521541950113, 28.324032758432956),\n",
       "   'relevant rank per query': (58.082417582417584, 151.32563976834248)}]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ltr.train import train_biased_listNet\n",
    "\n",
    "params = Namespace(epochs=10, \n",
    "                    lr=1e-4,\n",
    "                    batch_size=1,\n",
    "                    metrics={\"ndcg@10\", \"precision@10\", \"recall@10\"})\n",
    "\n",
    "biased_net = LTRModel(15, width=20)\n",
    "train_biased_listNet(biased_net, params, data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the results\n",
    "Since we randomly simulate clicks and use them to train our model, for the evaluation we train and save 10 different models and inspect the average and std over them.\n",
    "\n",
    "**IMPORTANT** Run the following cell to store your models and results. After it finishes, make sure to push the results to the git repo.\n",
    "\n",
    "_Estimated time on Codespaces_: 5m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Model 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\"ndcg@10\": (0.6773043080431509, 0.3250625909905689)\n",
      "\t\"recall@10\": (0.8044218238637209, 0.3324953027741621)\n",
      "\t\"precision@10\": (0.15389755011135864, 0.13377905601844914)\n",
      "Training Model 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\"ndcg@10\": (0.6559571370785954, 0.3518663062901273)\n",
      "\t\"recall@10\": (0.7547113530311487, 0.3653888759062017)\n",
      "\t\"precision@10\": (0.14476614699331852, 0.13653524019868285)\n",
      "Training Model 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\"ndcg@10\": (0.7121973859644857, 0.3233688039552177)\n",
      "\t\"recall@10\": (0.8128065989064286, 0.3264564892489743)\n",
      "\t\"precision@10\": (0.15345211581291765, 0.1292185629725136)\n",
      "Training Model 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\"ndcg@10\": (0.6882138274139388, 0.33620359041156)\n",
      "\t\"recall@10\": (0.7873332433466063, 0.34294387414555866)\n",
      "\t\"precision@10\": (0.15077951002227175, 0.13416596420057986)\n",
      "Training Model 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\"ndcg@10\": (0.6868901551987109, 0.3243101864424063)\n",
      "\t\"recall@10\": (0.8024668480419823, 0.3338772023165869)\n",
      "\t\"precision@10\": (0.15389755011135858, 0.1331114649825888)\n",
      "Training Model 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\"ndcg@10\": (0.6943624060753261, 0.3187839072166773)\n",
      "\t\"recall@10\": (0.8052154375749293, 0.3251552745070508)\n",
      "\t\"precision@10\": (0.15122494432071273, 0.12943105138073518)\n",
      "Training Model 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\"ndcg@10\": (0.6567824568334288, 0.34787731060031546)\n",
      "\t\"recall@10\": (0.7715321532333193, 0.35952661118414475)\n",
      "\t\"precision@10\": (0.14565701559020044, 0.1327625874763277)\n",
      "Training Model 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\"ndcg@10\": (0.7181465398251373, 0.31849599673377504)\n",
      "\t\"recall@10\": (0.8190578785233573, 0.3245620826980737)\n",
      "\t\"precision@10\": (0.15902004454342988, 0.13924685119253463)\n",
      "Training Model 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\"ndcg@10\": (0.7014993169731559, 0.33141985907797666)\n",
      "\t\"recall@10\": (0.8060706452230099, 0.32921584520384944)\n",
      "\t\"precision@10\": (0.15278396436525618, 0.13263661734062054)\n",
      "Training Model 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\"ndcg@10\": (0.592810160767414, 0.3511124024234709)\n",
      "\t\"recall@10\": (0.7485331585456045, 0.3751283420964054)\n",
      "\t\"precision@10\": (0.14565701559020044, 0.13994933206896656)\n"
     ]
    }
   ],
   "source": [
    "from ltr.utils import create_results\n",
    "from ltr.train import train_biased_listNet\n",
    "\n",
    "seed(42)\n",
    "params = Namespace(epochs=20, \n",
    "                    lr=1e-4,\n",
    "                    batch_size=1,\n",
    "                    metrics={\"ndcg@10\", \"precision@10\", \"recall@10\"})\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    print('Training Model', i)\n",
    "    biased_net = LTRModel(15, width=20)\n",
    "    create_results(data, biased_net, \n",
    "                train_biased_listNet, \n",
    "                biased_net,\n",
    "                f\"./outputs/biased_listNet_{i}.json\",\n",
    "                params)\n",
    "\n",
    "    torch.save(biased_net.state_dict(), f\"./outputs/biased_listNet_{i}\")\n",
    "    \n",
    "# biased_net = LTRModel(15, width=20)\n",
    "# biased_net.load_state_dict(torch.load('./outputs/biased_listNet_0'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Unbiased ListNet\n",
    "\n",
    "### Unbiased ListNet loss function\n",
    "\n",
    "Now, we use IPS to have an unbiased ListNet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 20, 15]) torch.Size([1, 20]) torch.Size([1, 20])\n",
      "torch.Size([1, 20, 1]) torch.Size([1, 20])\n",
      "tensor(0., grad_fn=<SumBackward0>)\n"
     ]
    }
   ],
   "source": [
    "from ltr.loss import unbiased_listNet_loss\n",
    "\n",
    "unbiased_net = LTRModel(data.num_features, width=20)\n",
    "propensity = logging_policy.propensity\n",
    "\n",
    "\n",
    "\n",
    "for features, clicks, positions in train_dl:\n",
    "    print(features.shape, clicks.shape, positions.shape)\n",
    "    output = biased_net(features)\n",
    "    print(output.shape, clicks.shape)\n",
    "    loss = unbiased_listNet_loss(output, clicks, propensity[positions.data.numpy()])\n",
    "    print(loss)\n",
    "    break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.6960)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "output = torch.tensor(\n",
    "    [\n",
    "        [\n",
    "            [0.3367],\n",
    "            [0.1288],\n",
    "            [0.2345],\n",
    "            [0.2303],\n",
    "            [-1.1229],\n",
    "            [-0.1863],\n",
    "            [2.2082],\n",
    "            [-0.6380],\n",
    "            [0.4617],\n",
    "            [0.2674],\n",
    "        ]\n",
    "    ]\n",
    ")\n",
    "target = torch.tensor(\n",
    "    [\n",
    "        [\n",
    "            0.5349,\n",
    "            0.8094,\n",
    "            1.1103,\n",
    "            -1.6898,\n",
    "            -0.9890,\n",
    "            0.9580,\n",
    "            1.3221,\n",
    "            0.8172,\n",
    "            -0.7658,\n",
    "            -0.7506,\n",
    "        ]\n",
    "    ]\n",
    ")\n",
    "propensity = torch.tensor(\n",
    "    [\n",
    "        [\n",
    "            1.3525,\n",
    "            0.6863,\n",
    "            -0.3278,\n",
    "            0.7950,\n",
    "            0.2815,\n",
    "            0.0562,\n",
    "            0.5227,\n",
    "            -0.2384,\n",
    "            -0.0499,\n",
    "            0.5263,\n",
    "        ]\n",
    "    ]\n",
    ")\n",
    "\n",
    "loss = unbiased_listNet_loss(output, target, propensity)\n",
    "print(loss)\n",
    "assert torch.allclose(loss, torch.tensor(2.6961), atol=0.1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unbiased ListNet training\n",
    "Now use `unbiased_listNet_loss` to train an LTR model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'metrics_val': [{'dcg': (12.369525123706113, 12.030741031272468),\n",
       "   'dcg@03': (7.1829902546886935, 8.018866305452054),\n",
       "   'dcg@05': (7.626980132490122, 8.428239520968798),\n",
       "   'dcg@10': (8.491479450305436, 8.746365443461205),\n",
       "   'dcg@20': (9.20914525509095, 9.376538354705115),\n",
       "   'ndcg': (0.525809381585071, 0.30793461049494947),\n",
       "   'ndcg@03': (0.3642994280154696, 0.4027074415067183),\n",
       "   'ndcg@05': (0.3657143267508853, 0.39671391744035),\n",
       "   'ndcg@10': (0.39120069590421835, 0.38355251902695814),\n",
       "   'ndcg@20': (0.4155510304995906, 0.3722456194923025),\n",
       "   'precision@01': (0.4230769230769231, 0.4940474068717357),\n",
       "   'precision@03': (0.19963369963369962, 0.22061045871207083),\n",
       "   'precision@05': (0.13626373626373625, 0.15655387972314838),\n",
       "   'precision@10': (0.08901098901098901, 0.09428801964445115),\n",
       "   'precision@20': (0.055219780219780225, 0.06212983608396073),\n",
       "   'recall@01': (0.28068419675562534, 0.3985784275780513),\n",
       "   'recall@03': (0.3569204604918891, 0.42564070437699375),\n",
       "   'recall@05': (0.38197681439439685, 0.42856362036522966),\n",
       "   'recall@10': (0.4769323167674816, 0.43326433834031913),\n",
       "   'recall@20': (0.5450417714153978, 0.42600255806364),\n",
       "   'relevant rank': (33.183673469387756, 31.21202899288288),\n",
       "   'relevant rank per query': (80.4065934065934, 138.92503140950296)},\n",
       "  {'dcg': (15.94867299482188, 12.669174643882451),\n",
       "   'dcg@03': (11.322405386556854, 8.216091661535943),\n",
       "   'dcg@05': (12.006791357836311, 8.649293973728554),\n",
       "   'dcg@10': (13.097890996960613, 9.315847274441056),\n",
       "   'dcg@20': (13.965285459994774, 10.116027136753145),\n",
       "   'ndcg': (0.7273213151070869, 0.2877176350412264),\n",
       "   'ndcg@03': (0.6157269367697304, 0.3944968296668172),\n",
       "   'ndcg@05': (0.623248154171093, 0.38647169976477086),\n",
       "   'ndcg@10': (0.6492071380308273, 0.3612777462359261),\n",
       "   'ndcg@20': (0.6754244507273993, 0.33753571332001414),\n",
       "   'precision@01': (0.6593406593406593, 0.47393095940324886),\n",
       "   'precision@03': (0.32600732600732596, 0.22901830084015512),\n",
       "   'precision@05': (0.21978021978021978, 0.16523029564142858),\n",
       "   'precision@10': (0.13626373626373628, 0.11674757546625594),\n",
       "   'precision@20': (0.08104395604395605, 0.0765715082133296),\n",
       "   'recall@01': (0.47719363969363965, 0.43849148965846774),\n",
       "   'recall@03': (0.5963665912841738, 0.4237845310211071),\n",
       "   'recall@05': (0.6469160418336243, 0.41958779734859514),\n",
       "   'recall@10': (0.7351217463854827, 0.3710784805110026),\n",
       "   'recall@20': (0.814684308365627, 0.3194779603270324),\n",
       "   'relevant rank': (21.39455782312925, 27.62222259824623),\n",
       "   'relevant rank per query': (51.84065934065934, 122.17296285313098)},\n",
       "  {'dcg': (16.204722930465223, 13.055146377151312),\n",
       "   'dcg@03': (11.55059589399277, 8.467676348366695),\n",
       "   'dcg@05': (12.520782014214644, 8.911061796099542),\n",
       "   'dcg@10': (13.577022617348398, 9.719196388895856),\n",
       "   'dcg@20': (14.415446066861795, 10.689428377353236),\n",
       "   'ndcg': (0.7341529628920457, 0.2727509713079168),\n",
       "   'ndcg@03': (0.6218826979278104, 0.39174160324733015),\n",
       "   'ndcg@05': (0.6409249531026477, 0.3633759724671016),\n",
       "   'ndcg@10': (0.6630528121283511, 0.34304626509332353),\n",
       "   'ndcg@20': (0.6871340780626628, 0.3187819575137814),\n",
       "   'precision@01': (0.6153846153846154, 0.4865042554105199),\n",
       "   'precision@03': (0.34432234432234426, 0.24929962677177372),\n",
       "   'precision@05': (0.24395604395604398, 0.1882299220697169),\n",
       "   'precision@10': (0.14725274725274726, 0.12825169222426136),\n",
       "   'precision@20': (0.08516483516483517, 0.08483808285136991),\n",
       "   'recall@01': (0.4471570096570096, 0.44106871004868203),\n",
       "   'recall@03': (0.6212500411676236, 0.42000455007545806),\n",
       "   'recall@05': (0.6963398323288433, 0.38947458708351357),\n",
       "   'recall@10': (0.7744056767408417, 0.35348378853900314),\n",
       "   'recall@20': (0.8295819107632294, 0.310060492903293),\n",
       "   'relevant rank': (18.766439909297052, 25.61687649282513),\n",
       "   'relevant rank per query': (45.472527472527474, 116.36328493311397)},\n",
       "  {'dcg': (15.763670313380597, 12.680962752574974),\n",
       "   'dcg@03': (10.717997250073354, 8.492115540274483),\n",
       "   'dcg@05': (11.83978608005729, 8.597244611608573),\n",
       "   'dcg@10': (13.083256194460358, 9.311074922837635),\n",
       "   'dcg@20': (14.022106401968635, 10.312782339319698),\n",
       "   'ndcg': (0.7060571195700128, 0.27232509312598535),\n",
       "   'ndcg@03': (0.5694436634711942, 0.40150106839391947),\n",
       "   'ndcg@05': (0.5997792140366944, 0.36456787105277993),\n",
       "   'ndcg@10': (0.6340061478657679, 0.33695436144308605),\n",
       "   'ndcg@20': (0.6621743528136109, 0.3110319223977939),\n",
       "   'precision@01': (0.5714285714285714, 0.4948716593053935),\n",
       "   'precision@03': (0.3205128205128205, 0.25526300118619694),\n",
       "   'precision@05': (0.23296703296703292, 0.17355680898812864),\n",
       "   'precision@10': (0.1467032967032967, 0.12432282459149033),\n",
       "   'precision@20': (0.08653846153846154, 0.08482429256187254),\n",
       "   'recall@01': (0.4028096903096903, 0.4337813625441564),\n",
       "   'recall@03': (0.5785510734686559, 0.4381578479642926),\n",
       "   'recall@05': (0.6745425819601644, 0.40270519561231893),\n",
       "   'recall@10': (0.7708902818792929, 0.3500181036404224),\n",
       "   'recall@20': (0.840435937688685, 0.29977668853291384),\n",
       "   'relevant rank': (18.215419501133788, 24.832341903571148),\n",
       "   'relevant rank per query': (44.137362637362635, 116.88417216601411)},\n",
       "  {'dcg': (17.289825978775415, 13.095279638262642),\n",
       "   'dcg@03': (12.829046730934163, 8.517484589188838),\n",
       "   'dcg@05': (13.841413037839017, 9.027760852539807),\n",
       "   'dcg@10': (14.898411015347078, 9.864529914085281),\n",
       "   'dcg@20': (15.605391340529026, 10.82286309456826),\n",
       "   'ndcg': (0.7901870205416082, 0.2602838058267432),\n",
       "   'ndcg@03': (0.6941442563928577, 0.3799939999324899),\n",
       "   'ndcg@05': (0.7093159883708773, 0.35082848827863033),\n",
       "   'ndcg@10': (0.730123824133416, 0.32658360042966866),\n",
       "   'ndcg@20': (0.7459009136583963, 0.31124481850312863),\n",
       "   'precision@01': (0.7362637362637363, 0.44065797045633887),\n",
       "   'precision@03': (0.37545787545787546, 0.24965593734850722),\n",
       "   'precision@05': (0.26263736263736265, 0.19731625290122046),\n",
       "   'precision@10': (0.15604395604395607, 0.1327716301028721),\n",
       "   'precision@20': (0.08846153846153847, 0.08772989362238948),\n",
       "   'recall@01': (0.5350048760763046, 0.4324296208683789),\n",
       "   'recall@03': (0.6812419723134009, 0.3993092490520588),\n",
       "   'recall@05': (0.7382599543313829, 0.3710559475942926),\n",
       "   'recall@10': (0.8058119078723475, 0.3261438219857692),\n",
       "   'recall@20': (0.8505615263857021, 0.29595866113037245),\n",
       "   'relevant rank': (16.72108843537415, 24.064854449528394),\n",
       "   'relevant rank per query': (40.51648351648352, 112.21661378607165)},\n",
       "  {'dcg': (17.195545784228184, 12.810477729456665),\n",
       "   'dcg@03': (12.698146117014758, 8.33898029114416),\n",
       "   'dcg@05': (13.578376393497543, 8.959368525492172),\n",
       "   'dcg@10': (14.779914415606891, 9.604930236375665),\n",
       "   'dcg@20': (15.64667560741512, 10.734850530326588),\n",
       "   'ndcg': (0.7864267177721567, 0.2539228431412179),\n",
       "   'ndcg@03': (0.6874279528580406, 0.37032518131911507),\n",
       "   'ndcg@05': (0.6976180405604973, 0.35160678400765527),\n",
       "   'ndcg@10': (0.7267981063072535, 0.3200861684229844),\n",
       "   'ndcg@20': (0.7470628599373075, 0.29981943341148537),\n",
       "   'precision@01': (0.7142857142857143, 0.4517539514526257),\n",
       "   'precision@03': (0.37179487179487175, 0.2477948202459738),\n",
       "   'precision@05': (0.254945054945055, 0.1911582603434245),\n",
       "   'precision@10': (0.1565934065934066, 0.12896647302814093),\n",
       "   'precision@20': (0.09093406593406596, 0.08871925125252601),\n",
       "   'recall@01': (0.5191100566100566, 0.43358290170026736),\n",
       "   'recall@03': (0.6779910565624852, 0.4040151899872107),\n",
       "   'recall@05': (0.724894153465582, 0.38153505099199186),\n",
       "   'recall@10': (0.8152649548253944, 0.32274109233267234),\n",
       "   'recall@20': (0.8698065670593143, 0.2800380823718931),\n",
       "   'relevant rank': (16.063492063492063, 23.12032129404202),\n",
       "   'relevant rank per query': (38.92307692307692, 111.86817504694864)},\n",
       "  {'dcg': (17.387005618031846, 12.928163784394073),\n",
       "   'dcg@03': (12.884537407179586, 8.400658860636097),\n",
       "   'dcg@05': (14.03645607157155, 9.070204882487126),\n",
       "   'dcg@10': (14.982145267893705, 9.812991527491508),\n",
       "   'dcg@20': (15.821315060235433, 10.846289455831258),\n",
       "   'ndcg': (0.7933867960048048, 0.2555339198355119),\n",
       "   'ndcg@03': (0.6952937040405555, 0.3717818907230547),\n",
       "   'ndcg@05': (0.7142150096613816, 0.3426424806420925),\n",
       "   'ndcg@10': (0.7350469270130265, 0.32143367314595844),\n",
       "   'ndcg@20': (0.7525407139389219, 0.30390273507066146),\n",
       "   'precision@01': (0.7307692307692307, 0.44356009979503064),\n",
       "   'precision@03': (0.380952380952381, 0.2474358296526968),\n",
       "   'precision@05': (0.27032967032967037, 0.19527073653838398),\n",
       "   'precision@10': (0.1565934065934066, 0.1289664730281409),\n",
       "   'precision@20': (0.09065934065934066, 0.08799103597953647),\n",
       "   'recall@01': (0.5324657485371772, 0.4308710970068537),\n",
       "   'recall@03': (0.688796917368346, 0.3957811438494026),\n",
       "   'recall@05': (0.7508727993618105, 0.3629576983359481),\n",
       "   'recall@10': (0.8100243620848017, 0.3276944752936501),\n",
       "   'recall@20': (0.8670135267662741, 0.28299587909398183),\n",
       "   'relevant rank': (15.90702947845805, 22.988569979000502),\n",
       "   'relevant rank per query': (38.543956043956044, 110.63212846224184)},\n",
       "  {'dcg': (17.523866181188076, 12.948645448305369),\n",
       "   'dcg@03': (13.1052934996338, 8.421803890078612),\n",
       "   'dcg@05': (14.11912455195393, 9.162739234697074),\n",
       "   'dcg@10': (15.08871706201455, 9.914779887063618),\n",
       "   'dcg@20': (15.951491846712717, 10.904938522333968),\n",
       "   'ndcg': (0.801835356340076, 0.2530322471554491),\n",
       "   'ndcg@03': (0.7081279656641839, 0.36713944142721827),\n",
       "   'ndcg@05': (0.7222240817579189, 0.34659752513467407),\n",
       "   'ndcg@10': (0.741166813437832, 0.3246911341977645),\n",
       "   'ndcg@20': (0.7622105400500684, 0.30091495732063667),\n",
       "   'precision@01': (0.7417582417582418, 0.43766762793467323),\n",
       "   'precision@03': (0.38461538461538464, 0.25160329320255526),\n",
       "   'precision@05': (0.27032967032967037, 0.19639302683090204),\n",
       "   'precision@10': (0.15604395604395604, 0.12941864193791022),\n",
       "   'precision@20': (0.09065934065934066, 0.08799103597953647),\n",
       "   'recall@01': (0.5434547595261882, 0.42990186198537217),\n",
       "   'recall@03': (0.6931467342181629, 0.39694636592111343),\n",
       "   'recall@05': (0.751101737090748, 0.36579750869561234),\n",
       "   'recall@10': (0.8059034829639224, 0.3337538217824482),\n",
       "   'recall@20': (0.8696586380652316, 0.2812564997854085),\n",
       "   'relevant rank': (15.571428571428571, 22.740675495584227),\n",
       "   'relevant rank per query': (37.73076923076923, 110.02426824435139)},\n",
       "  {'dcg': (17.330214068582436, 13.207910228866641),\n",
       "   'dcg@03': (12.882581484468966, 8.480200839268045),\n",
       "   'dcg@05': (13.885966211463554, 9.289238835673743),\n",
       "   'dcg@10': (14.904971445602753, 10.000475333878361),\n",
       "   'dcg@20': (15.73615118165672, 11.004439342450365),\n",
       "   'ndcg': (0.7931738797146851, 0.25547520913289157),\n",
       "   'ndcg@03': (0.697982464762242, 0.370262971760536),\n",
       "   'ndcg@05': (0.7141300312437963, 0.34664917213515795),\n",
       "   'ndcg@10': (0.733424767103135, 0.321946653029003),\n",
       "   'ndcg@20': (0.7525651550570105, 0.30284409087780717),\n",
       "   'precision@01': (0.7252747252747253, 0.44637573651845935),\n",
       "   'precision@03': (0.380952380952381, 0.25947927836519913),\n",
       "   'precision@05': (0.265934065934066, 0.20012072192805685),\n",
       "   'precision@10': (0.15604395604395604, 0.12899339041657484),\n",
       "   'precision@20': (0.09065934065934066, 0.08830270362620353),\n",
       "   'recall@01': (0.5269254554968841, 0.4343476716890595),\n",
       "   'recall@03': (0.6758953958129782, 0.4029390782166631),\n",
       "   'recall@05': (0.7404332389222499, 0.373241627239405),\n",
       "   'recall@10': (0.8061429870495803, 0.3268268913382208),\n",
       "   'recall@20': (0.8743997303063237, 0.2746573944307595),\n",
       "   'relevant rank': (15.682539682539682, 22.700532701529994),\n",
       "   'relevant rank per query': (38.0, 107.89107245960398)},\n",
       "  {'dcg': (17.512711042147473, 13.018075569723296),\n",
       "   'dcg@03': (13.078251223534897, 8.219219319490527),\n",
       "   'dcg@05': (14.10242018630932, 9.068721623183114),\n",
       "   'dcg@10': (15.151236710117752, 10.126163464677372),\n",
       "   'dcg@20': (15.95423732291754, 10.986056701411107),\n",
       "   'ndcg': (0.8015394988681902, 0.25308307054637896),\n",
       "   'ndcg@03': (0.7111472312554672, 0.35935187080519004),\n",
       "   'ndcg@05': (0.7234233284568686, 0.34334280306367687),\n",
       "   'ndcg@10': (0.7414543060762429, 0.3251933263356741),\n",
       "   'ndcg@20': (0.7612900028271374, 0.30379990824740194),\n",
       "   'precision@01': (0.7417582417582418, 0.43766762793467323),\n",
       "   'precision@03': (0.3882783882783884, 0.2459127984248652),\n",
       "   'precision@05': (0.27032967032967037, 0.19639302683090204),\n",
       "   'precision@10': (0.1587912087912088, 0.139089149724435),\n",
       "   'precision@20': (0.09148351648351649, 0.08908260922736393),\n",
       "   'recall@01': (0.5462020122734409, 0.4312110011345721),\n",
       "   'recall@03': (0.6965455789631614, 0.3878699749903636),\n",
       "   'recall@05': (0.7547540371716196, 0.3626775786257558),\n",
       "   'recall@10': (0.8034516307867956, 0.3327224641267104),\n",
       "   'recall@20': (0.8742974516326165, 0.2761526492157435),\n",
       "   'relevant rank': (15.151927437641723, 22.054088368039647),\n",
       "   'relevant rank per query': (36.714285714285715, 106.93705509299537)}]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ltr.train import train_unbiased_listNet\n",
    "\n",
    "params = Namespace(epochs=10, \n",
    "                    lr=1e-4,\n",
    "                    batch_size=1,\n",
    "                    propensity=logging_policy.propensity,\n",
    "                    metrics={\"ndcg@10\", \"precision@10\", \"recall@10\"})\n",
    "\n",
    "biased_net = LTRModel(15, width=20)\n",
    "train_unbiased_listNet(biased_net, params, data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the results\n",
    "Similar to the biased model, here we train 10 different unbiased models and save them to inspect the average and std over them.\n",
    "\n",
    "**IMPORTANT** Run the following cell to store your models and results. After it finishes, make sure to push the results to the git repo.\n",
    "\n",
    "_Estimated time on Codespaces_: 5m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Model 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\"ndcg@10\": (0.7345720591260813, 0.31756238607806153)\n",
      "\t\"recall@10\": (0.8227963427753812, 0.32144787027025856)\n",
      "\t\"precision@10\": (0.15879732739420938, 0.13894087570485597)\n",
      "Training Model 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\"ndcg@10\": (0.744471287469003, 0.31796050619668503)\n",
      "\t\"recall@10\": (0.8309308934947609, 0.31334906131372936)\n",
      "\t\"precision@10\": (0.16191536748329624, 0.14266593733177377)\n",
      "Training Model 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\"ndcg@10\": (0.7592335779266325, 0.30142357102180245)\n",
      "\t\"recall@10\": (0.8465454963686327, 0.29785618775360834)\n",
      "\t\"precision@10\": (0.16481069042316263, 0.14113766920086235)\n",
      "Training Model 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\"ndcg@10\": (0.7427452270998334, 0.31529649487536143)\n",
      "\t\"recall@10\": (0.8191097732202147, 0.31911737488495256)\n",
      "\t\"precision@10\": (0.15924276169265036, 0.14098083506342018)\n",
      "Training Model 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\"ndcg@10\": (0.7138324657246984, 0.3225163236353201)\n",
      "\t\"recall@10\": (0.8192312389417066, 0.3245247352412128)\n",
      "\t\"precision@10\": (0.15879732739420938, 0.1382982039733555)\n",
      "Training Model 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\"ndcg@10\": (0.757167630272573, 0.3075349321424616)\n",
      "\t\"recall@10\": (0.8388255993391589, 0.3050047418050537)\n",
      "\t\"precision@10\": (0.16436525612472164, 0.143840453079388)\n",
      "Training Model 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\"ndcg@10\": (0.7271636373737903, 0.3182060787987736)\n",
      "\t\"recall@10\": (0.8232024740474891, 0.315630779288533)\n",
      "\t\"precision@10\": (0.15946547884187084, 0.13695927665944377)\n",
      "Training Model 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\"ndcg@10\": (0.7278832913283729, 0.3195563083768278)\n",
      "\t\"recall@10\": (0.8245173618323101, 0.31718508135982215)\n",
      "\t\"precision@10\": (0.16035634743875282, 0.13802894199920715)\n",
      "Training Model 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\"ndcg@10\": (0.7269579126368901, 0.318835533058269)\n",
      "\t\"recall@10\": (0.8223376435055985, 0.31983318116936726)\n",
      "\t\"precision@10\": (0.15790645879732743, 0.13542338189407746)\n",
      "Training Model 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\"ndcg@10\": (0.7568805118809107, 0.3087979241018758)\n",
      "\t\"recall@10\": (0.8326419722757992, 0.310980819112721)\n",
      "\t\"precision@10\": (0.16191536748329624, 0.14328902049400014)\n"
     ]
    }
   ],
   "source": [
    "from ltr.utils import create_results\n",
    "from ltr.train import train_unbiased_listNet\n",
    "\n",
    "seed(42)\n",
    "params = Namespace(epochs=20, \n",
    "                    lr=1e-4,\n",
    "                    batch_size=1,\n",
    "                    propensity=logging_policy.propensity,\n",
    "                    metrics={\"ndcg@10\", \"precision@10\", \"recall@10\"})\n",
    "\n",
    "for i in range(10):\n",
    "    print('Training Model', i)\n",
    "    unbiased_net = LTRModel(15, width=20)\n",
    "    create_results(data, unbiased_net, \n",
    "                train_unbiased_listNet, \n",
    "                unbiased_net,\n",
    "                f\"./outputs/unbiased_listNet_{i}.json\",\n",
    "                params)\n",
    "\n",
    "    torch.save(unbiased_net.state_dict(), f\"./outputs/unbiased_listNet_{i}\")\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Propensity estimation\n",
    "\n",
    "In training our unbiased ListNet model, we assumed that we know propensity values.\n",
    "In practice, however, the propensity values have to be estimated from the clicks.\n",
    "There are several methods for estimating the propensities, such as dual learning algorithm (DLA) and regression-based EM.\n",
    "Here, we focus on DLA.\n",
    "\n",
    "### DLA\n",
    "\n",
    "IPS is based on the examination hypothesis that says $P(c=1)=P(r=1)\\times P(e=1)$, where $c$, $r$ and $e$ are click, relevance and examination signals, respectively.\n",
    "Initially, we are interested in $P(r=1)$, so in IPS we substitute $c$ with $\\hat{r}=\\frac{c}{P(e=1)}$.\n",
    "In practice, $P(e=1)$ is not given and should be estimated.\n",
    "DLA solves this by noticing that $\\hat(e)=\\frac{r}{P(r=1)}$ is also an unbiased estimation for the examination probability.\n",
    "This means that in DLA (as the name suggests), two models are trained at the same time:\n",
    "- Relevance prediction: A function $f$, modeled by `LTRModel` here, that estimates the relevance from the feature vectors.\n",
    "- Propensity prediction: A function $g$, modeled by `PropLTRModel` here, that estimates the propensity from the positions.\n",
    "\n",
    "Using the `unbiased_listNet_loss` loss function with the following signature:\n",
    "$$\n",
    "\\mathcal{L}_{\\text{unbiased}}\\big(\\text{predictions}, \\text{clicks}, \\text{propensities}\\big),\n",
    "$$\n",
    "\n",
    "the overall loss function is as follows:\n",
    "$$\n",
    "\\mathcal{L}_{\\text{DLA}} = \\underbrace{\\mathcal{L}_{\\text{unbiased}}\\bigg(f(x), c, \\sigma\\big(g(p)\\big)\\bigg)}_{\\text{relevance estimation}} + \\underbrace{\\mathcal{L}_{\\text{unbiased}} \\bigg(g(p), c, \\sigma\\big(f(x)\\big)\\bigg)}_{\\text{propensity estimation}},\n",
    "$$\n",
    "which means that the predictions of $g$ are used as the propensities for optimizing $f$, and the predictions of $f$ are used as the propensities for optimizing $g$.\n",
    "The $\\sigma()$ function is used to transform the logits to valid probability valules, as the propensities should be between 0 and 1."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logits to prob\n",
    "First, we need a function to transform the logits to valid probability values (between 0 and 1).\n",
    "Use the sigmoid function for this transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "probabilities: tensor([0.7130, 0.6204, 0.9876, 0.9999, 0.9999, 0.9989, 0.9999, 0.9061, 0.9996,\n",
      "        0.9997])\n"
     ]
    }
   ],
   "source": [
    "from ltr.train import logit_to_prob\n",
    "\n",
    "logits = 10 * torch.rand(10)\n",
    "probs = logit_to_prob(logits)\n",
    "\n",
    "# Print the propensities\n",
    "print('probabilities:', probs.squeeze())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Propensity estimation LTR model\n",
    "Then, we need a wrapper around the `LTRModel` that takes as input the positions (Long tensor) and outputs the logits for propensities.\n",
    "This new model uses one hot embedding as the input features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "probabilities: tensor([[0.4836, 0.4840, 0.5121, 0.4901, 0.5034, 0.4754, 0.5023, 0.4817, 0.4813,\n",
      "         0.5083, 0.5199, 0.5127, 0.4997, 0.4980, 0.5145, 0.4967, 0.4706]],\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "normalized with the first position: tensor([[1.0000, 1.0010, 1.0590, 1.0136, 1.0409, 0.9830, 1.0388, 0.9961, 0.9954,\n",
      "         1.0512, 1.0751, 1.0603, 1.0334, 1.0299, 1.0640, 1.0271, 0.9732]],\n",
      "       grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "from ltr.model import PropLTRModel\n",
    "\n",
    "prop_net = PropLTRModel(logging_policy.topk, width=200)\n",
    "\n",
    "logits = prop_net(torch.arange(17))\n",
    "probs = logit_to_prob(logits)\n",
    "\n",
    "# Print the propensities\n",
    "print('probabilities:', probs.T)\n",
    "\n",
    "# Print the normalized propensities\n",
    "print('normalized with the first position:', probs.T/probs.squeeze()[0])        "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DLA training\n",
    "Now we have all we need for the DLA implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True (unknown to the model) propensities: [1.         0.5        0.33333334 0.25       0.2        0.16666667\n",
      " 0.14285715 0.125      0.11111111 0.1        0.09090909 0.08333334\n",
      " 0.07692308 0.07142857 0.06666667 0.0625     0.05882353 0.05555556\n",
      " 0.05263158 0.05      ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'metrics_val': [{'dcg': (15.672601131673868, 12.670944416171588),\n",
       "   'dcg@03': (10.864637640109986, 8.58744034478823),\n",
       "   'dcg@05': (11.951197321225818, 9.052342534575159),\n",
       "   'dcg@10': (12.856002950055794, 9.493796897597036),\n",
       "   'dcg@20': (13.769623783952575, 10.392400962867471),\n",
       "   'ndcg': (0.7034074589413044, 0.2858312977126358),\n",
       "   'ndcg@03': (0.5817174209223405, 0.4020492719066576),\n",
       "   'ndcg@05': (0.6040791414674389, 0.3778705578683698),\n",
       "   'ndcg@10': (0.6255722197220839, 0.35694013726806995),\n",
       "   'ndcg@20': (0.6495938246295985, 0.336058457903514),\n",
       "   'precision@01': (0.5824175824175825, 0.49316056422674454),\n",
       "   'precision@03': (0.3223443223443223, 0.2517365788469107),\n",
       "   'precision@05': (0.2351648351648352, 0.18299920517069107),\n",
       "   'precision@10': (0.13901098901098904, 0.11609540359714718),\n",
       "   'precision@20': (0.08296703296703298, 0.08211482854528097),\n",
       "   'recall@01': (0.4201881451881452, 0.43685418020079353),\n",
       "   'recall@03': (0.5881767042481328, 0.4347198820938236),\n",
       "   'recall@05': (0.6669589567941215, 0.41155232036191136),\n",
       "   'recall@10': (0.7348599660412848, 0.3756040992220334),\n",
       "   'recall@20': (0.807304645903547, 0.32615924420176257),\n",
       "   'relevant rank': (19.947845804988663, 26.005136438976514),\n",
       "   'relevant rank per query': (48.33516483516483, 115.00383545790015)}],\n",
       " 'train_loss_agg': [0.3331593, 126.69625, 3.7607646]}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ltr.train import train_DLA_listNet\n",
    "\n",
    "params = Namespace(epochs=1, \n",
    "                    lr=1e-4,\n",
    "                    batch_size=1,\n",
    "                    prop_lr=1e-3,\n",
    "                    prop_net=PropLTRModel(logging_policy.topk, width=256),\n",
    "                    metrics={\"ndcg@10\", \"precision@10\", \"recall@10\"})\n",
    "\n",
    "biased_net = LTRModel(15, width=256)\n",
    "print('True (unknown to the model) propensities:', logging_policy.propensity.data.numpy())\n",
    "train_DLA_listNet(biased_net, params, data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the results\n",
    "Similar to the biased model, here we train 10 different unbiased models and save them to inspect the average and std over them.\n",
    "\n",
    "**IMPORTANT** Run the following cell to store your models and results. After it finishes, make sure to push the results to the git repo.\n",
    "\n",
    "_Estimated time on Codespaces_: < 10m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Model 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\"ndcg@10\": (0.7431118123278635, 0.31142344826215723)\n",
      "\t\"recall@10\": (0.8355003032980237, 0.30792983563105447)\n",
      "\t\"precision@10\": (0.1616926503340758, 0.13856658474983816)\n",
      "Training Model 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\"ndcg@10\": (0.7021966213701517, 0.3278832524082581)\n",
      "\t\"recall@10\": (0.7859916336629292, 0.3428878275734683)\n",
      "\t\"precision@10\": (0.1534521158129176, 0.1369176204493416)\n",
      "Training Model 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\"ndcg@10\": (0.7268707763157533, 0.31510894956654284)\n",
      "\t\"recall@10\": (0.823162939801221, 0.3198831063691657)\n",
      "\t\"precision@10\": (0.1579064587973274, 0.13443300109930062)\n",
      "Training Model 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\"ndcg@10\": (0.7435726515506391, 0.3068126764734612)\n",
      "\t\"recall@10\": (0.8363906549220319, 0.30673302488659776)\n",
      "\t\"precision@10\": (0.16191536748329624, 0.14109619192704181)\n",
      "Training Model 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\"ndcg@10\": (0.7337240326761805, 0.31205820352730673)\n",
      "\t\"recall@10\": (0.8237666768650654, 0.3143967788085563)\n",
      "\t\"precision@10\": (0.15746102449888646, 0.13561298240807956)\n",
      "Training Model 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\"ndcg@10\": (0.7187305309410691, 0.3196967358282181)\n",
      "\t\"recall@10\": (0.8195859532260685, 0.3172723262131661)\n",
      "\t\"precision@10\": (0.15501113585746104, 0.1312202872875018)\n",
      "Training Model 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\"ndcg@10\": (0.7439000859327877, 0.3110453211973936)\n",
      "\t\"recall@10\": (0.8342762674971506, 0.3099251648508929)\n",
      "\t\"precision@10\": (0.16213808463251672, 0.1415500213689873)\n",
      "Training Model 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\"ndcg@10\": (0.6678732834088622, 0.3425555855417103)\n",
      "\t\"recall@10\": (0.7637974828496248, 0.3586684557811937)\n",
      "\t\"precision@10\": (0.14543429844098, 0.12970018804563668)\n",
      "Training Model 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\"ndcg@10\": (0.7153890366679488, 0.3149084607180106)\n",
      "\t\"recall@10\": (0.8246399462074819, 0.3174006322267088)\n",
      "\t\"precision@10\": (0.15746102449888646, 0.13279172673877104)\n",
      "Training Model 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\"ndcg@10\": (0.722976072711674, 0.32058479864376066)\n",
      "\t\"recall@10\": (0.8190228705163854, 0.3219972982306116)\n",
      "\t\"precision@10\": (0.15501113585746107, 0.13572559228680917)\n"
     ]
    }
   ],
   "source": [
    "from ltr.utils import create_results\n",
    "from ltr.train import train_DLA_listNet\n",
    "\n",
    "seed(42)\n",
    "params = Namespace(epochs=20, \n",
    "                    lr=1e-4,\n",
    "                    batch_size=1,\n",
    "                    prop_lr=1e-3,\n",
    "                    prop_net=None,\n",
    "                    metrics={\"ndcg@10\", \"precision@10\", \"recall@10\"})\n",
    "\n",
    "for i in range(10):\n",
    "    print('Training Model', i)\n",
    "    dla_net = LTRModel(15, width=256)\n",
    "    params.prop_net = PropLTRModel(logging_policy.topk, width=256)\n",
    "    create_results(data, dla_net, \n",
    "                train_DLA_listNet, \n",
    "                dla_net,\n",
    "                f\"./outputs/DLA_listNet_{i}.json\",\n",
    "                params)\n",
    "\n",
    "    torch.save(dla_net.state_dict(), f\"./outputs/DLA_listNet_{i}\")\n",
    "    torch.save(params.prop_net.state_dict(), f\"./outputs/DLA_listNet_prop_{i}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Comparing the models\n",
    "\n",
    "You have implemented three models: biased, unbiased with oracle propensity values, and unbiased with DLA-estimated propensity values.\n",
    "Given the training results and evaluation results, please elaborate on the ranking performance of these three models in `analysis.md`. See that file for further details.\n",
    "\n",
    "Note that you need to submit the result files created in `outputs/` for full credit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           ndcg  ndcg@20  precision@05  recall@20\n",
      "biased    0.743    0.702         0.247      0.866\n",
      "unbiased  0.794    0.760         0.265      0.894\n",
      "DLA       0.779    0.743         0.258      0.883\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ndcg</th>\n",
       "      <th>ndcg@20</th>\n",
       "      <th>precision@05</th>\n",
       "      <th>recall@20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>biased</th>\n",
       "      <td>0.743</td>\n",
       "      <td>0.702</td>\n",
       "      <td>0.247</td>\n",
       "      <td>0.866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unbiased</th>\n",
       "      <td>0.794</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DLA</th>\n",
       "      <td>0.779</td>\n",
       "      <td>0.743</td>\n",
       "      <td>0.258</td>\n",
       "      <td>0.883</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           ndcg  ndcg@20  precision@05  recall@20\n",
       "biased    0.743    0.702         0.247      0.866\n",
       "unbiased  0.794    0.760         0.265      0.894\n",
       "DLA       0.779    0.743         0.258      0.883"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def aggregate_results(model_name):\n",
    "    aggregated_metrics = {}\n",
    "    for i in range(10):\n",
    "        with open(f\"./outputs/{model_name}_{i}.json\", \"r\") as reader:\n",
    "            result = json.load(reader)\n",
    "            for metric, (v, std) in result['test_metrics'].items():\n",
    "                aggregated_metrics.setdefault(metric, []).append(v)\n",
    "    return {metric: np.mean(vals) for metric, vals in aggregated_metrics.items()}\n",
    "\n",
    "biased = aggregate_results('biased_listNet')\n",
    "unbiased = aggregate_results('unbiased_listNet')\n",
    "DLA = aggregate_results('DLA_listNet')\n",
    "\n",
    "# save the aggregated output files\n",
    "for model_avg_results, model_name in zip([biased, unbiased, DLA], [\"biased_listNet\", \"unbiased_listNet\", \"DLA_listNet\"]):\n",
    "    json.dump(model_avg_results, open(f\"outputs/{model_name}_avg.json\", \"wt\"))\n",
    "\n",
    "# display a handful of metrics\n",
    "print_metrics = [\"ndcg\", \"ndcg@20\", \"precision@05\", \"recall@20\"]\n",
    "print_biased = {metric: v for metric, v in biased.items() if metric in print_metrics}\n",
    "print_unbiased = {metric: v for metric, v in unbiased.items() if metric in print_metrics}\n",
    "print_DLA = {metric: v for metric, v in DLA.items() if metric in print_metrics}\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option(\"display.precision\", 3)\n",
    "df = pd.DataFrame([print_biased, print_unbiased, print_DLA], index=[\"biased\", \"unbiased\", \"DLA\"])\n",
    "print(df)\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remember to submit your outputs!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IR1_2023",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c2c5ccf7e153c3826497608a13106df1b3c5c34cecf259281315c8b06c776444"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
